import os
import re
import asyncio
import httpx
from typing import Optional
from google import genai
from google.genai import types
from app.core.key_manager import key_rotator
from app.core.github_auth import get_installation_access_token
from app.core.repomix import get_repomix_script
from app.core.event_bus import emit, emit_thought, emit_code_diff, EventType

MODEL_NAME = "gemini-3-flash-preview"
MODEL_NAME_PRO = "gemini-2.5-pro-exp-03-25"  # System 2: Deep reasoning

# Global set to track repos where user has allowed retry (bypasses duplicate PR check)
RETRY_ALLOWED_REPOS: set[str] = set()


# ============================================================================
# FIX PARSER: Extract code fixes from Gemini's response
# ============================================================================
def parse_fix_from_response(response: str) -> dict:
    """
    Parses the structured response from Gemini to extract:
    - File paths and their corrected content
    - Verification command
    - PR title and body
    """
    result = {
        "files": [],
        "verification_command": None,
        "pr_title": None,
        "pr_body": None
    }
    
    # Extract file blocks: **File: path** followed by ```language ... ```
    file_pattern = r'\*\*File:\s*([^\*\n`]+)\*\*\s*```(\w+)?\s*\n(.*?)```'
    file_matches = re.findall(file_pattern, response, re.DOTALL)
    
    for match in file_matches:
        filepath = match[0].strip()
        # language = match[1]  # e.g., 'tsx', 'python'
        content = match[2].strip()
        
        if filepath and content:
            result["files"].append({
                "path": filepath,
                "content": content
            })
    
    # Extract verification command
    verify_pattern = r'## ğŸ§ª VERIFICATION COMMAND\s*```(?:bash)?\s*\n(.*?)```'
    verify_match = re.search(verify_pattern, response, re.DOTALL)
    if verify_match:
        result["verification_command"] = verify_match.group(1).strip()
    
    # Extract PR title - multiple patterns for robustness
    title_patterns = [
        r'\*\*Title\*\*:\s*(.+?)(?:\n|$)',           # **Title**: text
        r'Title:\s*(.+?)(?:\n|$)',                   # Title: text
        r'## ğŸ“ PR DESCRIPTION.*?\*\*Title\*\*:\s*(.+?)(?:\n|$)',  # Under PR section
    ]
    for pattern in title_patterns:
        title_match = re.search(pattern, response, re.IGNORECASE)
        if title_match:
            result["pr_title"] = title_match.group(1).strip()
            break
    
    # Extract PR body - multiple patterns for robustness
    body_patterns = [
        r'\*\*Body\*\*:\s*(.+?)(?:\n(?:â•|#|```)|$)',  # **Body**: text until separator
        r'Body:\s*(.+?)(?:\n(?:â•|#|```)|$)',          # Body: text
    ]
    for pattern in body_patterns:
        body_match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
        if body_match:
            result["pr_body"] = body_match.group(1).strip()
            break
    
    # Fallback defaults if parsing failed
    if not result["pr_title"]:
        result["pr_title"] = "fix: Automated repair by TALOS Agent"
    if not result["pr_body"]:
        result["pr_body"] = "This PR contains automated fixes generated by the TALOS self-healing pipeline."
    
    return result


# ============================================================================
# DUPLICATE PR CHECK: Prevent creating PRs for already-fixed errors
# ============================================================================
async def check_existing_talos_pr(
    token: str,
    repo_full_name: str,
    error_signature: str = ""
) -> Optional[dict]:
    """
    Check if TALOS already has an open PR for this repo.
    Returns PR info if exists, None otherwise.
    
    This prevents duplicate PRs when:
    1. A fix is already waiting to be merged
    2. The same error triggers another webhook
    
    UNLESS: User has clicked "Allow Retry" to bypass this check.
    
    Cost: 1 API request (FREE - within rate limits)
    """
    # Check if user has allowed retry for this repo
    if repo_full_name in RETRY_ALLOWED_REPOS:
        print(f"   ğŸ”„ Retry allowed for {repo_full_name} - skipping duplicate check")
        RETRY_ALLOWED_REPOS.discard(repo_full_name)  # Clear the flag after use
        return None  # Proceed with new PR
    
    url = f"https://api.github.com/repos/{repo_full_name}/pulls"
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28"
    }
    
    params = {
        "state": "open",
        "per_page": 10,  # Only check recent PRs
        "sort": "created",
        "direction": "desc"
    }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(url, headers=headers, params=params)
            
            if response.status_code == 200:
                prs = response.json()
                
                # Look for TALOS-created PRs (branch starts with fix/talos-)
                for pr in prs:
                    head_ref = pr.get("head", {}).get("ref", "")
                    body = pr.get("body", "")
                    
                    # Check if this is a TALOS PR
                    if head_ref.startswith("fix/talos-") or "TALOS" in body:
                        print(f"   ğŸ” Found existing TALOS PR: #{pr['number']} - {pr['title']}")
                        return {
                            "number": pr["number"],
                            "url": pr["html_url"],
                            "title": pr["title"],
                            "branch": head_ref,
                            "created_at": pr["created_at"]
                        }
                
                return None  # No existing TALOS PR
            else:
                print(f"   âš ï¸ Could not check PRs: {response.status_code}")
                return None  # Proceed anyway if check fails
                
    except Exception as e:
        print(f"   âš ï¸ PR check error: {e}")
        return None  # Proceed anyway if check fails


# ============================================================================
# PR CREATION: Open Pull Request via GitHub API (Guide Section 8)
# ============================================================================
async def create_pull_request(
    token: str,
    repo_full_name: str,
    branch_name: str,
    title: str,
    body: str,
    base_branch: str = "main"
) -> Optional[str]:
    """
    Creates a Pull Request via GitHub API.
    Returns the PR URL if successful, None otherwise.
    """
    url = f"https://api.github.com/repos/{repo_full_name}/pulls"
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28"
    }
    
    # Add TALOS signature to the body
    enhanced_body = f"""## ğŸ¤– Automated Fix by TALOS Agent

{body}

---
*This PR was automatically generated by the TALOS Self-Healing Pipeline.*
*Please review the changes before merging.*
"""
    
    payload = {
        "title": title,
        "body": enhanced_body,
        "head": branch_name,
        "base": base_branch
    }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, headers=headers, json=payload)
            
            if response.status_code == 201:
                pr_data = response.json()
                return pr_data.get("html_url")
            else:
                print(f"   âŒ GitHub API Error: {response.status_code} - {response.text}")
                return None
                
    except Exception as e:
        print(f"   âŒ PR Creation Exception: {e}")
        return None


# ============================================================================
# PERCEPTION LAYER: Log Normalization (From Guide Section 4.1)
# ============================================================================
def normalize_log(raw_log: str) -> str:
    """
    Sanitize and normalize raw CI/CD logs.
    Strips ANSI codes, progress bars, and irrelevant noise.
    """
    # 1. Strip ANSI color codes
    ansi_pattern = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
    clean = ansi_pattern.sub('', raw_log)
    
    # 2. Remove npm download progress noise
    clean = re.sub(r'(npm notice|npm WARN|added \d+ packages).*\n?', '', clean)
    
    # 3. Remove timestamps like [2026-01-29T01:38:59]
    clean = re.sub(r'\[\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}[^\]]*\]', '', clean)
    
    # 4. Collapse multiple blank lines
    clean = re.sub(r'\n{3,}', '\n\n', clean)
    
    return clean.strip()


def extract_stack_trace(log: str) -> dict:
    """
    Extract the DNA of the error: file paths, line numbers, error type.
    """
    result = {
        "error_type": "Unknown",
        "hot_files": [],  # Files mentioned in the stack trace
        "error_message": ""
    }
    
    # Detect error type
    error_patterns = {
        "SyntaxError": r"(SyntaxError|Unexpected token|Parse error)",
        "TypeError": r"TypeError",
        "ReferenceError": r"(ReferenceError|is not defined)",
        "ModuleNotFoundError": r"(ModuleNotFoundError|Cannot find module|Module not found)",
        "IndentationError": r"IndentationError",
        "ImportError": r"ImportError",
    }
    
    for error_name, pattern in error_patterns.items():
        if re.search(pattern, log, re.IGNORECASE):
            result["error_type"] = error_name
            break
    
    # Extract file paths and line numbers (e.g., "at /path/file.js:42:10")
    file_patterns = [
        r'at\s+(?:\w+\s+)?\(?([^:\s]+):(\d+)(?::\d+)?\)?',  # JS stack trace
        r'File "([^"]+)", line (\d+)',  # Python stack trace
        r'([^\s:]+\.(?:js|ts|jsx|tsx|py|rs)):(\d+)',  # Generic file:line
    ]
    
    for pattern in file_patterns:
        matches = re.findall(pattern, log)
        for match in matches:
            filepath, line = match[0], match[1]
            if not any(x in filepath for x in ['node_modules', 'site-packages', '/usr/lib']):
                result["hot_files"].append({"file": filepath, "line": int(line)})
    
    # Extract the actual error message (first line after Error:)
    error_msg_match = re.search(r'(Error|Exception):\s*(.+?)(?:\n|$)', log)
    if error_msg_match:
        result["error_message"] = error_msg_match.group(2).strip()
    
    return result


# ============================================================================
# CONTEXTUAL ENGINE: Root vs Inner File Detection (From Guide Section 5)
# ============================================================================
def analyze_dependency_graph(box, hot_files: list, project_type: str) -> dict:
    """
    Build dependency graph to distinguish Root (caller) vs Inner (callee) files.
    Uses dependency-cruiser for JS/TS, or import analysis for Python.
    """
    print("ğŸ”— TALOS: Building dependency graph...")
    
    result = {
        "crash_site": None,  # Where the error occurred (Inner)
        "patient_zero": None,  # Where the bug originated (Root)
        "dependency_chain": []
    }
    
    if not hot_files:
        return result
    
    # The crash site is typically the first file in the stack trace
    crash_file = hot_files[0]["file"] if hot_files else None
    result["crash_site"] = crash_file
    
    if not crash_file:
        return result
    
    if project_type == "nodejs":
        # Use dependency-cruiser to find who imports the crash file
        dep_cmd = f"npx --yes dependency-cruiser --output-type json {crash_file} 2>/dev/null || echo '{{}}'"
        dep_result = box.run_command(dep_cmd)
        
        # Fallback: Simple grep for imports
        if not dep_result['stdout'].strip() or dep_result['stdout'].strip() == '{}':
            crash_basename = os.path.basename(crash_file)
            import_search = box.run_command(
                f"grep -rl \"import.*from.*{crash_basename}\" --include='*.js' --include='*.ts' --include='*.jsx' --include='*.tsx' . 2>/dev/null | head -5"
            )
            if import_search['stdout'].strip():
                result["dependency_chain"] = import_search['stdout'].strip().split('\n')
                
    elif project_type == "python":
        # Find who imports the crash module
        crash_basename = os.path.basename(crash_file)
        module_name = crash_basename.replace('.py', '')
        import_search = box.run_command(
            f"grep -rl \"import {module_name}\\|from {module_name}\" --include='*.py' . 2>/dev/null | head -5"
        )
        if import_search['stdout'].strip():
            result["dependency_chain"] = import_search['stdout'].strip().split('\n')
    
    return result


def correlate_with_git_diff(box, hot_files: list, dependency_chain: list) -> dict:
    """
    The 'Patient Zero' Algorithm (Guide Section 5.2):
    Correlate stack trace with git diff to find the ACTUAL source of the bug.
    
    Logic:
    1. If crash_file was modified â†’ it's likely the source
    2. If crash_file was NOT modified but a caller was â†’ caller is Patient Zero
    """
    print("ğŸ”¬ TALOS: Correlating with git history...")
    
    result = {
        "modified_files": [],
        "patient_zero": None,
        "diagnosis": ""
    }
    
    # Get list of recently changed files
    diff_result = box.run_command("git diff --name-only HEAD~1 2>/dev/null || git diff --name-only HEAD 2>/dev/null || echo ''")
    modified_files = [f.strip() for f in diff_result['stdout'].strip().split('\n') if f.strip()]
    result["modified_files"] = modified_files
    
    if not modified_files:
        # Fallback: check staged/unstaged changes
        diff_result = box.run_command("git status --short | awk '{print $2}'")
        modified_files = [f.strip() for f in diff_result['stdout'].strip().split('\n') if f.strip()]
        result["modified_files"] = modified_files
    
    # Triangulation: Stack Trace + Dependency Graph + Git History
    hot_file_paths = [h["file"] for h in hot_files]
    
    for hot_file in hot_file_paths:
        # Check if this hot file was modified
        hot_basename = os.path.basename(hot_file)
        for modified in modified_files:
            if hot_basename in modified or modified in hot_file:
                result["patient_zero"] = modified
                result["diagnosis"] = f"The error occurred in '{hot_file}', and this file WAS recently modified. This is the Patient Zero."
                return result
    
    # If crash file wasn't modified, check the callers
    for caller in dependency_chain:
        caller_basename = os.path.basename(caller)
        for modified in modified_files:
            if caller_basename in modified or modified in caller:
                result["patient_zero"] = modified
                result["diagnosis"] = f"The error manifested in a callee file, but the bug is in '{modified}' (a caller that was recently modified and passed bad data)."
                return result
    
    # Fallback: Just report what was modified
    if modified_files:
        result["patient_zero"] = modified_files[0]
        result["diagnosis"] = f"Could not determine exact causation. Recently modified files: {modified_files}"
    
    return result


async def run_healing_mission(payload: dict, run_id: str | None = None):
    """
    The Main Event Loop: Trigger -> Auth -> Scout -> Reason -> Plan
    Now with real-time event broadcasting for the Neural Dashboard.
    """
    # Generate run_id if not provided (for backward compatibility)
    if run_id is None:
        import uuid
        run_id = str(uuid.uuid4())[:8]
    
    repo_full_name = payload.get("repository", {}).get("full_name")
    installation_id = payload.get("installation", {}).get("id")
    repo_url = payload.get("repository", {}).get("clone_url")
    
    print(f"ğŸš€ TALOS: Mission Start for {repo_full_name} (Run ID: {run_id})")
    
    # ğŸ’¾ PERSIST: Create healing run in database
    from app.db.supabase import create_healing_run, update_healing_run, HealingRun, get_installation
    db_installation_id = None
    try:
        # Look up the installation UUID from the GitHub installation ID
        if installation_id:
            installation = await get_installation(int(installation_id))
            if installation and installation.id:
                db_installation_id = installation.id
    except Exception as lookup_err:
        print(f"âš ï¸ TALOS: Could not look up installation: {lookup_err}")
    
    try:
        await create_healing_run(HealingRun(
            run_id=run_id,
            repo_full_name=repo_full_name,
            installation_id=db_installation_id,  # Use the UUID, not the GitHub ID
            status="running"
        ))
        print(f"ğŸ’¾ TALOS: Run {run_id} saved to database")
    except Exception as db_err:
        print(f"âš ï¸ TALOS: Could not save run to DB: {db_err}")
    
    # ğŸ¬ BROADCAST: Mission Start
    await emit(
        run_id, EventType.MISSION_START,
        "ğŸš€ Mission Initiated",
        f"TALOS is healing {repo_full_name}",
        metadata={"repo": repo_full_name, "installation_id": installation_id}
    )

    try:
        token = await get_installation_access_token(installation_id)
        print(f"ğŸ” TALOS: Authenticated.")
        await emit(run_id, EventType.SCOUTING, "ğŸ” Authenticated", "Obtained GitHub installation token")
    except Exception as e:
        print(f"âŒ TALOS: Auth Failed: {e}")
        await update_healing_run(run_id, status="failure", error_type="auth_failed")
        await emit(run_id, EventType.FAILURE, "âŒ Authentication Failed", str(e))
        return

    from app.core.sandbox import TaskSandbox
    
    try:
        # ğŸ¬ BROADCAST: Cloning
        await emit(run_id, EventType.CLONING, "ğŸ“¦ Cloning Repository", f"Spinning up isolated sandbox for {repo_full_name}")
        
        with TaskSandbox(repo_url, token) as box:
            print("ğŸ“¦ TALOS: Repo cloned.")
            await emit(run_id, EventType.CLONING, "ğŸ“¦ Repository Cloned", "Isolated E2B sandbox ready")
            
            # --- PHASE 0: POLYGLOT SCOUT (The Brain) ---
            print("ğŸ”­ TALOS: Identifying language and project structure...")
            await emit(run_id, EventType.SCOUTING, "ğŸ”­ Scouting Project", "Detecting language, framework, and structure...")
            
            # 1. Search for key manifest files
            has_package_json = box.run_command("find . -name package.json -not -path '*/node_modules/*' | head -n 1")
            has_requirements = box.run_command("find . -name requirements.txt -not -path '*/venv/*' | head -n 1")
            has_pyproject = box.run_command("find . -name pyproject.toml | head -n 1")
            has_cargo = box.run_command("find . -name Cargo.toml | head -n 1")

            work_dir = "."
            test_command = "echo 'No tests detected'" # Default safety

            # 2. Decide Strategy based on evidence
            if has_package_json['stdout'].strip():
                project_type_display = "Node.js / JavaScript"
                print("âœ¨ Detected: Node.js Project")
                file_path = has_package_json['stdout'].strip()
                work_dir = os.path.dirname(file_path) or "."
                
                # ENHANCED: Multi-phase validation for Node.js
                pkg_content = box.read_file(file_path)
                has_build = '"build"' in pkg_content
                has_lint = '"lint"' in pkg_content
                has_test = '"test"' in pkg_content and 'no test specified' not in pkg_content
                
                # Construct smart command chain
                commands = ["npm install"]
                
                if has_lint:
                    commands.append("npm run lint")
                elif has_build:
                    commands.append("npm run build")
                else:
                    commands.append("npx --yes acorn --silent --ecma2020 --module *.js 2>&1 || npx --yes tsc --noEmit 2>&1 || echo 'Syntax check skipped'")
                
                if has_test:
                    commands.append("npm test")
                else:
                    commands.append("echo '[TALOS] No test script found - relying on lint/build for validation'")
                
                test_command = " && ".join(commands)
                
            elif has_requirements['stdout'].strip() or has_pyproject['stdout'].strip():
                project_type_display = "Python"
                print("âœ¨ Detected: Python Project")
                if has_requirements['stdout'].strip():
                    work_dir = os.path.dirname(has_requirements['stdout'].strip())
                    test_command = "pip install -r requirements.txt && pytest"
                else:
                    test_command = "pip install . && pytest"
                    
            elif has_cargo['stdout'].strip():
                print("âœ¨ Detected: Rust Project")
                file_path = has_cargo['stdout'].strip()
                work_dir = os.path.dirname(file_path)
                test_command = "cargo test"
                
            else:
                print("âš ï¸ Unknown Project Type. Defaulting to root exploration.")

            print(f"ğŸ“ Working Directory: '{work_dir}'")
            print(f"ğŸ› ï¸ Test Command: '{test_command}'")
            
            await emit(run_id, EventType.SCOUTING, f"âœ¨ Detected: {project_type_display if 'project_type_display' in dir() else 'Unknown'}", 
                      f"Working in: {work_dir}")

            # --- PHASE A: ACTIVATE THE EYES (Repomix) ---
            print("ğŸ‘ï¸ TALOS: Reading codebase...")
            await emit(run_id, EventType.READING_CODE, "ğŸ‘ï¸ Reading Codebase", "Assembling repository context with Repomix...")
            
            box.write_file("repomix_script.py", get_repomix_script())
            repo_context_result = box.run_command("python3 repomix_script.py")
            repo_context = repo_context_result['stdout']
            
            # --- PHASE B: THE PAIN SIGNAL ---
            print(f"ğŸ•µï¸ TALOS: Reproducing error...")
            await emit(run_id, EventType.ANALYZING, "ğŸ•µï¸ Reproducing Error", f"Running: {test_command[:50]}...")
            
            # Execute the DYNAMIC command found in Phase 0
            full_cmd = f"cd {work_dir} && {test_command}"
            test_result = box.run_command(full_cmd) 
            
            raw_error_log = test_result['stdout'] + "\n" + test_result['stderr']
            
            # ============================================================
            # NEW: PERCEPTION LAYER (Guide Section 4.1)
            # ============================================================
            print("ğŸ” TALOS: Normalizing and analyzing error log...")
            await emit(run_id, EventType.ANALYZING, "ğŸ” Analyzing Error Log", "Stripping noise, extracting stack trace DNA...")
            
            # Step 1: Sanitize the log (strip ANSI, noise)
            clean_log = normalize_log(raw_error_log)
            
            # Step 2: Extract stack trace DNA
            stack_analysis = extract_stack_trace(clean_log)
            print(f"   ğŸ“Š Error Type: {stack_analysis['error_type']}")
            print(f"   ğŸ“‚ Hot Files: {[h['file'] for h in stack_analysis['hot_files'][:3]]}")
            
            await emit(run_id, EventType.DIAGNOSING, f"ğŸ“Š Error Classification: {stack_analysis['error_type']}", 
                      f"Message: {stack_analysis['error_message'][:100]}..." if stack_analysis['error_message'] else "Analyzing hot files...",
                      metadata={"error_type": stack_analysis['error_type'], "hot_files": stack_analysis['hot_files'][:3]})
            
            # Determine project type for dependency analysis
            project_type = "nodejs" if has_package_json['stdout'].strip() else "python" if has_requirements['stdout'].strip() else "unknown"
            
            # ============================================================
            # NEW: ROOT VS INNER ANALYSIS (Guide Section 5)
            # ============================================================
            await emit(run_id, EventType.ANALYZING, "ğŸ”¬ Tracing Dependency Graph", "Distinguishing root cause from crash site...")
            
            dep_graph = analyze_dependency_graph(box, stack_analysis['hot_files'], project_type)
            git_correlation = correlate_with_git_diff(box, stack_analysis['hot_files'], dep_graph['dependency_chain'])
            
            if git_correlation['patient_zero']:
                print(f"   ğŸ¯ Patient Zero: {git_correlation['patient_zero']}")
                print(f"   ğŸ’¡ Diagnosis: {git_correlation['diagnosis']}")
                await emit(run_id, EventType.DIAGNOSING, f"ğŸ¯ Patient Zero: {git_correlation['patient_zero']}", 
                          git_correlation['diagnosis'],
                          metadata={"patient_zero": git_correlation['patient_zero'], "modified_files": git_correlation['modified_files']})
            
            # ============================================================
            # NEW: READ PATIENT ZERO FILE DIRECTLY (Critical for accurate fixes!)
            # ============================================================
            patient_zero_content = ""
            if git_correlation['patient_zero']:
                print(f"ğŸ“„ TALOS: Reading Patient Zero file content...")
                pz_file = git_correlation['patient_zero']
                try:
                    pz_read = box.run_command(f"cat '{pz_file}'")
                    if pz_read['stdout'].strip():
                        patient_zero_content = f"\n\n{'='*60}\nğŸ”´ PATIENT ZERO FILE CONTENT: {pz_file}\n{'='*60}\n{pz_read['stdout']}\n{'='*60}"
                        print(f"   âœ… Read {len(pz_read['stdout'])} chars from Patient Zero")
                except Exception as e:
                    print(f"   âš ï¸ Could not read Patient Zero: {e}")
            
            # Also read any other modified files
            modified_files_content = ""
            for mod_file in git_correlation.get('modified_files', [])[:3]:  # Limit to 3
                if mod_file != git_correlation.get('patient_zero'):
                    try:
                        mod_read = box.run_command(f"cat '{mod_file}'")
                        if mod_read['stdout'].strip():
                            modified_files_content += f"\n\n=== MODIFIED FILE: {mod_file} ===\n{mod_read['stdout']}"
                    except:
                        pass

            # --- PHASE B.5: DEEP SYNTAX SCAN (for when test script is missing) ---
            # If we only got "Missing script: test" error, we need to dig deeper
            if "Missing script" in clean_log or "no test specified" in clean_log.lower():
                print("ğŸ” TALOS: Test script missing - performing deep syntax scan...")
                
                # Find all JS/TS/JSX/TSX files and look for obvious syntax errors
                scan_cmd = """
                find . -type f \\( -name "*.js" -o -name "*.jsx" -o -name "*.ts" -o -name "*.tsx" \\) \
                -not -path '*/node_modules/*' -exec grep -l -E \
                '(^xport |^impor |^retur |^functio |^cons |^le |^va |function [a-zA-Z]+\\)|=> \\{$)' {} \\; 2>/dev/null
                """
                suspicious_files = box.run_command(scan_cmd)
                
                if suspicious_files['stdout'].strip():
                    print(f"ğŸš¨ TALOS: Found suspicious files with potential syntax errors!")
                    # Read the content of suspicious files to give Gemini real context
                    for f in suspicious_files['stdout'].strip().split('\n')[:5]:  # Limit to 5 files
                        content = box.run_command(f"cat '{f.strip()}'")
                        clean_log += f"\n\n=== SUSPICIOUS FILE: {f.strip()} ===\n{content['stdout']}"
                        clean_log += f"\n[TALOS HINT: Check for typos like 'xport' instead of 'export', 'retur' instead of 'return', missing parentheses, etc.]"
            
            # ============================================================
            # PHASE C: THE THINKING (Gemini 3) - ReAct Pattern (Guide Section 6)
            # ============================================================
            print("ğŸ§  TALOS: Engaging cognitive core...")
            await emit(run_id, EventType.THINKING, "ğŸ§  Engaging Cognitive Core", 
                      "Gemini 3 is analyzing the error and generating a fix...",
                      metadata={"model": MODEL_NAME})
            
            # Build the enhanced prompt with all our analysis
            prompt = f"""
            You are Talos, an autonomous site reliability engineer (Species: Gemini 3).
            Your role is to ACT as a "Translation Layer" - turning opaque error logs into clear diagnosis and fixes.
            
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            ğŸ“‹ MISSION CONTEXT
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            Project Type: {project_type.upper()}
            Working Directory: {work_dir}
            Test Command Used: {test_command}
            
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            ğŸ”¬ STACK TRACE ANALYSIS (Pre-processed)
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            Error Classification: {stack_analysis['error_type']}
            Error Message: {stack_analysis['error_message']}
            Hot Files (Crash Sites): {stack_analysis['hot_files']}
            
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            ğŸ¯ ROOT VS INNER FILE ANALYSIS (Patient Zero Detection)
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            Crash Site (Inner): {dep_graph['crash_site']}
            Dependency Chain (Callers): {dep_graph['dependency_chain']}
            Recently Modified Files: {git_correlation['modified_files']}
            Patient Zero (Root Cause): {git_correlation['patient_zero']}
            Diagnosis: {git_correlation['diagnosis']}
            
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            ğŸ“ CLEANED ERROR LOG
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {clean_log}
            
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            ï¿½ PATIENT ZERO FILE (THE BROKEN CODE - FIX THIS!)
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {patient_zero_content if patient_zero_content else "Could not read Patient Zero file"}
            
            {modified_files_content if modified_files_content else ""}
            
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            ğŸ“¦ REPOSITORY CONTEXT (Repomix)
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {repo_context}
            
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            ğŸ¯ YOUR MISSION (OODA Loop - Guide Section 2.2)
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            
            You are an autonomous Site Reliability Engineer. Your job is to DIAGNOSE and FIX bugs.
            
            CLASSIFICATION GUIDE:
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ 1. SYNTAX ERROR                                             â”‚
            â”‚    - Typos (xportâ†’export, returâ†’return, functioâ†’function)   â”‚
            â”‚    - Missing brackets, parentheses, semicolons              â”‚
            â”‚    - Invalid JSX/TSX structure                              â”‚
            â”‚    - Malformed imports/exports                              â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚ 2. LOGIC BUG                                                â”‚
            â”‚    - Off-by-one errors in loops                             â”‚
            â”‚    - Wrong conditional operators (< vs <=, == vs ===)       â”‚
            â”‚    - Null/undefined access without checks                   â”‚
            â”‚    - Race conditions, async/await misuse                    â”‚
            â”‚    - Wrong algorithm implementation                         â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚ 3. CONFIGURATION ISSUE                                      â”‚
            â”‚    - Missing dependencies in package.json/requirements.txt  â”‚
            â”‚    - Wrong script definitions                               â”‚
            â”‚    - Environment variable issues                            â”‚
            â”‚    - Build/webpack/vite config errors                       â”‚
            â”‚    - TypeScript config issues                               â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚ 4. DEPENDENCY CONFLICT                                      â”‚
            â”‚    - Version mismatches between packages                    â”‚
            â”‚    - Peer dependency warnings                               â”‚
            â”‚    - Breaking changes from package updates                  â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚ 5. RUNTIME ERROR                                            â”‚
            â”‚    - API call failures                                      â”‚
            â”‚    - Database connection issues                             â”‚
            â”‚    - File system errors                                     â”‚
            â”‚    - Memory/performance issues                              â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚ 6. REACT PURITY VIOLATION (React 19 Compiler)               â”‚
            â”‚    - Math.random() called during render                     â”‚
            â”‚    - Date.now() called during render                        â”‚
            â”‚    - crypto.randomUUID() called during render               â”‚
            â”‚    - Any non-deterministic function in component body       â”‚
            â”‚                                                             â”‚
            â”‚    FIX PATTERN (PRESERVE FUNCTIONALITY!):                   â”‚
            â”‚    'use client';                                            â”‚
            â”‚    import {{ useState, useEffect }} from 'react';           â”‚
            â”‚    const [val, setVal] = useState(null);                    â”‚
            â”‚    useEffect(() => {{ setVal(Math.random()); }}, []);       â”‚
            â”‚    if (val === null) return <p>Loading...</p>;              â”‚
            â”‚    // Then use val in render                                â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            
            âš ï¸ CRITICAL RULES:
            
            1. MINIMAL CHANGES ONLY!
               - ONLY fix what is broken
               - DO NOT rewrite or "improve" working code
               - DO NOT change text content, messages, or UI copy
               - DO NOT add features or enhancements
               - If original says <p>Lucky Number!</p>, keep EXACTLY that text
               - If original says <p>Try again.</p>, keep EXACTLY that text
            
            2. NEVER DELETE FUNCTIONALITY!
               - Make the code WORK, not remove features
               - Preserve all original behavior and output
            
            3. PRESERVE ORIGINAL TEXT EXACTLY!
               - String literals, messages, and UI text must stay identical
               - Only change the CODE STRUCTURE, not the CONTENT
            
            CHAIN OF THOUGHT (CoT) - Reason step-by-step:
            
            **OBSERVE**: What does the error log tell us? What's the surface symptom?
            **ORIENT**: Is this the ROOT cause or a SYMPTOM of something deeper?
                       Use the Patient Zero analysis - which file actually changed?
                       Trace the dependency chain: Did the crash happen in an inner file
                       because a root file passed bad data?
            **DECIDE**: What category of bug is this? What's the minimal fix?
            **ACT**: Generate the precise fix.
            
            RESPONSE FORMAT:
            
            ## ğŸ”´ ERROR CLASSIFICATION
            [Choose: Syntax Error | Logic Bug | Configuration Issue | Dependency Conflict | Runtime Error]
            
            ## ğŸ“ LOCATION
            - **Patient Zero (Root Cause File)**: [filename:line]
            - **Crash Site (Where error manifested)**: [filename:line]
            - **Why here?**: [Brief explanation of root vs inner]
            
            ## ğŸ’¬ HUMAN-READABLE EXPLANATION
            [Explain in plain English what went wrong. Be specific about:
             - What the developer changed
             - Why that change broke the build
             - The causal chain from change to failure]
            
            ## âœ… THE FIX
            Provide the COMPLETE corrected file(s):
            
            **File: [filename]**
            ```[language]
            [Complete corrected code - not just a snippet]
            ```
            
            ## ğŸ§ª VERIFICATION COMMAND
            ```bash
            [The exact command to run to verify the fix works]
            ```
            
            ## ğŸ“ PR DESCRIPTION (for automated PR creation)
            **Title**: [Short descriptive title]
            **Body**: [2-3 sentence description of what was fixed and why]
            """
            
            fix_plan = await generate_with_retry(prompt)
            
            # ============================================================
            # PHASE D: OUTPUT (The Face - Guide Section 3.4)
            # ============================================================
            print("\n" + "â•"*60)
            print("ğŸ§  TALOS DIAGNOSIS & SOLUTION")
            print("â•"*60)
            print(fix_plan)
            print("â•"*60 + "\n")
            
            # ğŸ¬ BROADCAST: Stream the thought process to the frontend
            await emit(run_id, EventType.THOUGHT_STREAM, "ğŸ’­ Gemini's Analysis", 
                      fix_plan[:1500] + "..." if len(fix_plan) > 1500 else fix_plan,
                      metadata={"full_response_length": len(fix_plan)})
            
            # ============================================================
            # PHASE E: VERIFICATION LOOP (Guide Section 7.2 - Red/Green/Refactor)
            # ============================================================
            print("ğŸ”„ TALOS: Verification Loop (Phase E)")
            await emit(run_id, EventType.VERIFYING, "ğŸ”„ Entering Verification Loop", "Testing the proposed fix...")
            
            # Step 1: Parse the fix from Gemini's response
            parsed_fix = parse_fix_from_response(fix_plan)
            current_fix_plan = fix_plan  # Track current plan for retry prompts
            
            if parsed_fix['files']:
                print(f"   ğŸ“„ Found {len(parsed_fix['files'])} file(s) to fix")
                await emit(run_id, EventType.APPLYING_FIX, f"ğŸ“„ Found {len(parsed_fix['files'])} file(s) to fix",
                          ", ".join([f["path"] for f in parsed_fix['files']]))
                
                verification_passed = False
                max_retries = 3
                last_error = ""
                
                for attempt in range(max_retries):
                    print(f"   ğŸ” Attempt {attempt + 1}/{max_retries}")
                    await emit(run_id, EventType.VERIFYING, f"ğŸ” Verification Attempt {attempt + 1}/{max_retries}", 
                              "Applying fixes and running tests...")
                    
                    # Step 2: Apply the fixes
                    for file_fix in parsed_fix['files']:
                        filepath = file_fix['path']
                        content = file_fix['content']
                        print(f"   ğŸ”§ Applying fix to: {filepath}")
                        
                        # ğŸ¬ BROADCAST: Show the code diff
                        try:
                            old_content = box.read_file(filepath)
                        except:
                            old_content = "(new file)"
                        await emit_code_diff(run_id, filepath, old_content[:500], content[:500])
                        
                        box.apply_fix(filepath, content)
                        
                        # Debug: Verify file was written correctly
                        print(f"   ğŸ“‹ Verifying file write...")
                        check_result = box.run_command(f"head -3 '{filepath}'")
                        print(f"   ğŸ“‹ First 3 lines: {check_result['stdout'][:100]}...")
                    
                    # Step 3: Re-run the test command to verify
                    # Use parsed verification command, or fall back to original test_command
                    verify_cmd = parsed_fix.get('verification_command') or test_command
                    print(f"   ğŸ§ª Verifying fix with: {verify_cmd}")
                    await emit(run_id, EventType.VERIFYING, "ğŸ§ª Running Verification", f"Command: {verify_cmd[:60]}...")
                    
                    verify_result = box.run_command(f"cd {work_dir} && {verify_cmd}")
                    
                    # Capture full output for debugging
                    full_output = verify_result['stdout'] + "\n" + verify_result['stderr']
                    
                    if verify_result['exit_code'] == 0:
                        print("   âœ… VERIFICATION PASSED! Fix is valid.")
                        await emit(run_id, EventType.SUCCESS, "âœ… Verification Passed!", "The fix has been validated successfully")
                        verification_passed = True
                        break
                    else:
                        last_error = full_output
                        print(f"   âŒ Verification failed!")
                        print(f"   ğŸ“‹ Full error output:")
                        print(f"   {full_output[:500]}")  # Show first 500 chars of error
                        
                        await emit(run_id, EventType.RETRY, f"âŒ Attempt {attempt + 1} Failed", 
                                  f"Error: {full_output[:200]}...")
                        
                        if attempt < max_retries - 1:
                            print("   ğŸ”„ Feeding error back to Gemini for retry...")
                            await emit(run_id, EventType.THINKING, "ğŸ”„ Re-analyzing with new error", 
                                      "Gemini is learning from the failure...")
                            
                            # Build retry prompt with the NEW error
                            retry_prompt = f"""Your previous fix attempt FAILED verification.

## PREVIOUS FIX ATTEMPT:
{current_fix_plan[:2000]}

## NEW ERROR AFTER APPLYING YOUR FIX:
```
{last_error[:2000]}
```

The original syntax errors may be fixed, but there is a NEW error now. 
You must address THIS new error, not the original one.

## REACT COMPILER / PURITY RULES (if applicable):
If the error mentions "impure function" or "Cannot call impure function during render":

IMPORTANT: You must PRESERVE the original functionality, not delete it!

### CORRECT FIX PATTERN (use this):
```tsx
'use client';
import {{ useState, useEffect }} from 'react';

export default function Home() {{
  const [randomValue, setRandomValue] = useState<number | null>(null);
  
  useEffect(() => {{
    setRandomValue(Math.random());
  }}, []);

  if (randomValue === null) return <p>Loading...</p>;

  return (
    <div>
      <h1>Title</h1>
      {{randomValue > 0.5 ? <p>Lucky!</p> : <p>Try again</p>}}
    </div>
  );
}}
```

### RULES:
1. Move impure calls (Math.random, Date.now) into useEffect
2. Store the result in useState  
3. Add 'use client' directive at top
4. Show loading state while value is null
5. NEVER just delete functionality - always preserve the original behavior
6. MINIMAL CHANGES ONLY - do NOT modify text content or UI copy!
   - If original has <p>Lucky Number!</p> â†’ keep EXACTLY <p>Lucky Number!</p>
   - If original has <p>Try again.</p> â†’ keep EXACTLY <p>Try again.</p>
   - ONLY change the code structure, NOT the content/strings

Please provide a COMPLETE corrected file that fixes THIS new error.
IMPORTANT: Keep all original text/strings EXACTLY as they were!

Use the exact same format as before with the code block labeled with the file path.

**File: [exact/path/to/file.ext]**
```language
// complete fixed code here
```

## ğŸ§ª VERIFICATION COMMAND
```bash
npm run lint
```
"""
                            print("   ğŸ¤– Re-prompting Gemini with new error...")
                            current_fix_plan = await generate_with_retry(retry_prompt)
                            print(f"   ğŸ“ New fix plan received")
                            
                            # Re-parse the new fix
                            parsed_fix = parse_fix_from_response(current_fix_plan)
                            if not parsed_fix['files']:
                                print("   âš ï¸ Could not parse new fix from Gemini response")
                                break
                
                # ============================================================
                # PHASE F: PR CREATION (Guide Section 2.2 - The Action Phase)
                # ============================================================
                if verification_passed:
                    print("ğŸ”€ TALOS: PR Creation (Phase F)")
                    await emit(run_id, EventType.CREATING_PR, "ğŸ”€ Checking for existing PRs", "Avoiding duplicate fixes...")
                    
                    # DUPLICATE PR CHECK: Don't create PR if one already exists
                    existing_pr = await check_existing_talos_pr(token, repo_full_name)
                    
                    if existing_pr:
                        print(f"   â­ï¸ Skipping PR creation - existing TALOS PR found: #{existing_pr['number']}")
                        await emit(run_id, EventType.SUCCESS, "â­ï¸ Fix Already Pending", 
                                  f"An existing TALOS PR is waiting to be merged: #{existing_pr['number']}",
                                  metadata={
                                      "existing_pr_url": existing_pr['url'],
                                      "existing_pr_number": existing_pr['number'],
                                      "reason": "duplicate_prevention"
                                  })
                        await emit(run_id, EventType.MISSION_END, "ğŸ No New PR Needed", 
                                  f"Merge the existing PR first: {existing_pr['url']}",
                                  metadata={"status": "skipped", "existing_pr": existing_pr['url']})
                        await update_healing_run(run_id, status="success", pr_url=existing_pr['url'])
                        return  # Exit early - don't create duplicate PR
                    
                    await emit(run_id, EventType.CREATING_PR, "ğŸ”€ Creating Pull Request", "Pushing verified fix to GitHub...")
                    
                    import time
                    branch_name = f"fix/talos-{int(time.time())}"
                    
                    # Step 1: Create branch
                    if box.create_branch(branch_name):
                        print(f"   ğŸŒ¿ Created branch: {branch_name}")
                        await emit(run_id, EventType.CREATING_PR, f"ğŸŒ¿ Branch Created: {branch_name}", "Committing changes...")
                        
                        # Step 2: Commit and push
                        commit_message = parsed_fix.get('pr_title', 'fix: Auto-healing by TALOS agent')
                        if box.commit_and_push(commit_message, branch_name):
                            print(f"   ğŸ“¤ Pushed to remote")
                            await emit(run_id, EventType.CREATING_PR, "ğŸ“¤ Pushed to Remote", "Opening Pull Request...")
                            
                            # Step 3: Create PR via GitHub API
                            pr_result = await create_pull_request(
                                token=token,
                                repo_full_name=repo_full_name,
                                branch_name=branch_name,
                                title=parsed_fix.get('pr_title', 'fix: Auto-healing by TALOS'),
                                body=parsed_fix.get('pr_body', fix_plan)
                            )
                            
                            if pr_result:
                                print(f"   ğŸ‰ PR Created: {pr_result}")
                                # ğŸ¬ FINAL SUCCESS BROADCAST
                                await emit(run_id, EventType.SUCCESS, "ğŸ‰ Mission Complete!", 
                                          f"Pull Request created successfully",
                                          metadata={"pr_url": pr_result, "branch": branch_name})
                                await emit(run_id, EventType.MISSION_END, "ğŸ Healing Complete", 
                                          f"PR: {pr_result}",
                                          metadata={"pr_url": pr_result, "status": "success"})
                                await update_healing_run(run_id, status="success", pr_url=pr_result)
                            else:
                                print("   âš ï¸ PR creation failed (see logs)")
                                await emit(run_id, EventType.FAILURE, "âš ï¸ PR Creation Failed", 
                                          "Fix was verified but PR could not be created")
                        else:
                            print("   âŒ Failed to push changes")
                            await emit(run_id, EventType.FAILURE, "âŒ Push Failed", "Could not push to remote")
                    else:
                        print("   âŒ Failed to create branch")
                        await emit(run_id, EventType.FAILURE, "âŒ Branch Creation Failed", "Could not create fix branch")
                else:
                    print("   âš ï¸ Verification failed after all retries. No PR created.")
                    print("   ğŸ¯ Human intervention required.")
                    await emit(run_id, EventType.FAILURE, "âš ï¸ Verification Failed", 
                              "All retry attempts exhausted. Human intervention required.",
                              metadata={"last_error": last_error[:500], "attempts": max_retries})
                    await emit(run_id, EventType.MISSION_END, "ğŸ Mission Incomplete", 
                              "Could not verify fix after multiple attempts",
                              metadata={"status": "failed", "reason": "verification_failed"})
                    await update_healing_run(run_id, status="failure", error_type="verification_failed")
            else:
                print("   âš ï¸ Could not parse fix from Gemini response")
                await emit(run_id, EventType.FAILURE, "âš ï¸ Parse Error", 
                          "Could not extract fix from Gemini's response")
                await emit(run_id, EventType.MISSION_END, "ğŸ Mission Incomplete", 
                          "Failed to parse fix from AI response",
                          metadata={"status": "failed", "reason": "parse_error"})
                await update_healing_run(run_id, status="failure", error_type="parse_error")

    except Exception as e:
        print(f"ğŸ’€ TALOS DIED: {e}")
        await emit(run_id, EventType.FAILURE, "ğŸ’€ Critical Error", str(e)[:500])
        await emit(run_id, EventType.MISSION_END, "ğŸ Mission Failed", 
                  f"Unhandled exception: {str(e)[:200]}",
                  metadata={"status": "error", "exception": str(e)[:500]})
        await update_healing_run(run_id, status="failure", error_type="exception")

async def generate_with_retry(prompt: str, context: str = "", thought_signature: str = None):
    """
    Generate content with Gemini, supporting:
    1. Key rotation on rate limits
    2. Thought signature preservation for multi-turn reasoning
    
    Thought Signatures (Guide Section 4.2):
    - Gemini 3 returns encrypted thought_signature tokens
    - Passing them back preserves the model's reasoning state
    - This improves multi-turn debugging conversations
    """
    max_retries = len(key_rotator.keys) * 2  # Allow more retries for 503s
    attempt = 0
    backoff = 5
    
    # Store thought signature for return
    new_thought_signature = None

    while attempt < max_retries:
        current_key = key_rotator.get_current_key()
        try:
            client = genai.Client(api_key=current_key)
            full_content = f"CONTEXT:\n{context}\n\nTASK:\n{prompt}" if context else prompt
            
            print(f"ğŸ¤– TALOS: Thinking with Key #{key_rotator.current_index + 1}...")

            # Build generation config
            gen_config = types.GenerateContentConfig(
                temperature=0.2,  # Lower temp for more deterministic fixes
                top_p=0.95,
            )
            
            # Include thought signature if available (multi-turn reasoning)
            if thought_signature:
                print(f"   ğŸ§  Using thought signature for continuity...")
                # Note: thought_signature handling depends on Gemini SDK version
                # Some versions use it in config, others in request metadata
            
            response = client.models.generate_content(
                model=MODEL_NAME,
                contents=full_content,
                config=gen_config
            )
            
            # Try to extract new thought signature from response
            # (Available in Gemini 3 responses for multi-turn reasoning)
            if hasattr(response, 'thought_signature'):
                new_thought_signature = response.thought_signature
                print(f"   ğŸ§  Captured thought signature for future turns")
            
            # Return both the text and signature
            return response.text

        except Exception as e:
            error_msg = str(e)
            print(f"âš ï¸ GEMINI ERROR on Key #{key_rotator.current_index + 1}: {error_msg}")
            
            if "429" in error_msg or "403" in error_msg:
                print(f"ğŸ›‘ Rate limited - switching keys (cooling {backoff}s)...")
                key_rotator.rotate()
                attempt += 1
                await asyncio.sleep(backoff)
            elif "503" in error_msg or "UNAVAILABLE" in error_msg or "overloaded" in error_msg.lower():
                # Model overloaded - wait and retry with same key
                backoff = min(backoff * 2, 30)  # Exponential backoff, max 30s
                print(f"ğŸ”„ Model overloaded - waiting {backoff}s before retry...")
                attempt += 1
                await asyncio.sleep(backoff)
            else:
                raise e

    raise Exception("All Gemini retries exhausted.")